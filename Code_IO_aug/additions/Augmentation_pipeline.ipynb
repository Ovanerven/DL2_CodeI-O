{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cc905b6",
   "metadata": {},
   "source": [
    "# Full augmentation pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080fa701",
   "metadata": {},
   "source": [
    "### Assembling a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996891ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 23647.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>reference_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In a 3D space, a drone is navigating towards a...</td>\n",
       "      <td># import necessary packages\\nimport numpy as n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Given a differential equation and its initial ...</td>\n",
       "      <td># import necessary packages\\nimport math\\nimpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Given a list of integers, what are all the pos...</td>\n",
       "      <td># import necessary packages\\nimport json\\n\\n# ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Given a set of numerical data points, what are...</td>\n",
       "      <td># import necessary packages\\nimport math\\nimpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Given an even number greater than 2, what are ...</td>\n",
       "      <td># import necessary packages\\nfrom random impor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  In a 3D space, a drone is navigating towards a...   \n",
       "1  Given a differential equation and its initial ...   \n",
       "2  Given a list of integers, what are all the pos...   \n",
       "3  Given a set of numerical data points, what are...   \n",
       "4  Given an even number greater than 2, what are ...   \n",
       "\n",
       "                                      reference_code  \n",
       "0  # import necessary packages\\nimport numpy as n...  \n",
       "1  # import necessary packages\\nimport math\\nimpo...  \n",
       "2  # import necessary packages\\nimport json\\n\\n# ...  \n",
       "3  # import necessary packages\\nimport math\\nimpo...  \n",
       "4  # import necessary packages\\nfrom random impor...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Function to read jsonl files\n",
    "def read_jsonl(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error decoding line in {filename}\")\n",
    "    return data\n",
    "\n",
    "def extract_context(prompt):\n",
    "    \"\"\"Extract just the problem context from the prompt.\"\"\"\n",
    "    # Split at \"Given the following output/input:\"\n",
    "    parts = re.split(r\"Given the following (output|input):\", prompt)\n",
    "    if len(parts) > 1:\n",
    "        raw_context = parts[0]\n",
    "        \n",
    "        # Remove template beginning\n",
    "        template_start = \"You are given a question that requires some input and output variables as follows:\\n\\n\"\n",
    "        if raw_context.startswith(template_start):\n",
    "            raw_context = raw_context[len(template_start):]\n",
    "        \n",
    "        return raw_context.strip()\n",
    "    return None\n",
    "\n",
    "def extract_reference_code(prompt):\n",
    "    \"\"\"Extract only the runnable Python code from the reference section.\"\"\"\n",
    "    # The reference code appears after this marker\n",
    "    marker = \"Tip: Here is a reference code snippet for this question.\"\n",
    "    if marker in prompt:\n",
    "        # Get everything after the marker\n",
    "        code_part = prompt.split(marker)[1].strip()\n",
    "        \n",
    "        # Look for actual Python code patterns\n",
    "        lines = code_part.split('\\n')\n",
    "        cleaned_lines = []\n",
    "        code_started = False\n",
    "        \n",
    "        for line in lines:\n",
    "            # Detect the start of actual code by looking for common Python patterns\n",
    "            if not code_started and (line.startswith('import ') or \n",
    "                                    line.startswith('from ') or \n",
    "                                    line.startswith('def ') or \n",
    "                                    line.startswith('class ') or \n",
    "                                    line.startswith('# ')):\n",
    "                code_started = True\n",
    "                \n",
    "            if code_started:\n",
    "                cleaned_lines.append(line)\n",
    "                \n",
    "        # Join the actual code lines\n",
    "        clean_code = '\\n'.join(cleaned_lines)\n",
    "        return clean_code\n",
    "    return None\n",
    "\n",
    "def process_data(input_file, max_rows=None):\n",
    "    \"\"\"Process the dataset and return a DataFrame with the extracted components.\"\"\"\n",
    "    data = read_jsonl(input_file)\n",
    "    \n",
    "    if max_rows is not None:\n",
    "        data = data[:max_rows]\n",
    "    \n",
    "    records = []\n",
    "    for item in tqdm(data):\n",
    "        if 'prompt' not in item:\n",
    "            continue\n",
    "        \n",
    "        context = extract_context(item['prompt'])\n",
    "        reference_code = extract_reference_code(item['prompt'])\n",
    "        \n",
    "        if context and reference_code:\n",
    "            records.append({\n",
    "                'context': context,\n",
    "                'reference_code': reference_code,\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# --- Configurable parameters ---\n",
    "NUM_ROWS = None  # Set to None to process all rows\n",
    "# OUTPUT_CSV = '../processed_data/extracted_contexts.csv'\n",
    "\n",
    "# Setup paths\n",
    "data_dir = '../generated_data'\n",
    "input_file = os.path.join(data_dir, 'ast-pyedur_full_subset.jsonl')\n",
    "\n",
    "# Process data and create DataFrame\n",
    "df = process_data(input_file, max_rows=NUM_ROWS)\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58894c73",
   "metadata": {},
   "source": [
    "### Generate input_generator prompt column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e7fb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DataFrame with 10000 rows to augmented_data_with_prompts.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to extract input and output specifications from context\n",
    "def extract_io_specs(context):\n",
    "    \"\"\"Extract input and output specifications from the problem context.\"\"\"\n",
    "    input_spec = \"\"\n",
    "    output_spec = \"\"\n",
    "    \n",
    "    # Try to find input specifications\n",
    "    input_match = re.search(r'Input:\\s*(.*?)(?=Output:|$)', context, re.DOTALL)\n",
    "    if input_match:\n",
    "        input_spec = input_match.group(1).strip()\n",
    "    \n",
    "    # Try to find output specifications\n",
    "    output_match = re.search(r'Output:\\s*(.*?)(?=\\n\\n|$)', context, re.DOTALL)\n",
    "    if output_match:\n",
    "        output_spec = output_match.group(1).strip()\n",
    "    \n",
    "    return input_spec, output_spec\n",
    "\n",
    "# Define the base input generator prompt template\n",
    "inputgen_prompt_template = \"\"\"\n",
    "You are an expert programmer tasked with creating an input generator function for a given code snippet. This function will be used to generate test inputs for the code.\n",
    "\n",
    "I'll provide you with a reference code implementation. Your job is to create a Python function called `input_generator()` that:\n",
    "\n",
    "- You need to provide a function named `input_generator` that generates the input arguments for the `main_solution` function.\n",
    "- The `input_generator` function should not require any input arguments, and each time it is called, it should return a set of input arguments that meet the requirements of the `main_solution` function.\n",
    "- The output of `input_generator` should always be a dictionary because we always call by `**kwargs` in the `main_solution` function.\n",
    "- Add some randomness in the `input_generator` function to ensure the input arguments are different each time it is called.\n",
    "- Please try to make the generated input arguments as reasonable as possible, try to avoid generating too complex or too trivial input variables, also the size of the variables should be reasonable, like less than 1KB.\n",
    "\n",
    "The input and output requirements for the main function are as follows:\n",
    "\n",
    "Input:\n",
    "{input_spec}\n",
    "\n",
    "Output:\n",
    "{output_spec}\n",
    "\n",
    "The input generator should ONLY generate the inputs, not execute the main function or process any outputs.\n",
    "\n",
    "Here is the reference code:    \n",
    "```python\t\n",
    "{reference_code}\n",
    "```\n",
    "Please respond with ONLY the input_generator() function definition. Your response should start with \"import\" statements if needed, followed by the function definition. Do not include any explanations or other text.\n",
    "\"\"\"\n",
    "\n",
    "# Function to create a customized prompt for each row\n",
    "def create_input_generator_prompt(row):\n",
    "    input_spec, output_spec = extract_io_specs(row['context'])\n",
    "    return inputgen_prompt_template.format(input_spec=input_spec, output_spec=output_spec, reference_code=row['reference_code'])\n",
    "\n",
    "# Apply the function to each row and add as a new column\n",
    "df['input_generator_prompt'] = df.apply(create_input_generator_prompt, axis=1)\n",
    "\n",
    "df.to_csv('../generated_data/augmented_data_with_prompts.csv', index=False) \n",
    "print(f\"Saved DataFrame with {len(df)} rows to augmented_data_with_prompts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70712517",
   "metadata": {},
   "source": [
    "### use deepseek api to generate input generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8db4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"sk-19ae0ae5f65940a2869149d2a0fe2c82\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f02b26f",
   "metadata": {},
   "source": [
    "### Old sequential api call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# from openai import OpenAI\n",
    "\n",
    "# def generate_input_generators(df, api_key, max_rows=None, temperature=0.3, batch_size=10, sleep_time=1):\n",
    "#     \"\"\"\n",
    "#     Generate input generators for each row in the DataFrame using the Deepseek API.\n",
    "    \n",
    "#     Args:\n",
    "#         df: DataFrame containing an 'input_generator_prompt' column\n",
    "#         api_key: Deepseek API key\n",
    "#         max_rows: Maximum number of rows to process (None for all rows)\n",
    "#         temperature: Temperature setting for the API (0.0 to 1.0)\n",
    "#         batch_size: Number of API calls before pausing to avoid rate limits\n",
    "#         sleep_time: Seconds to sleep between batches\n",
    "        \n",
    "#     Returns:\n",
    "#         DataFrame with a new 'input_generator' column containing the generated code\n",
    "#     \"\"\"\n",
    "#     # Create a copy to avoid modifying the original DataFrame\n",
    "#     result_df = df.copy()\n",
    "    \n",
    "#     # Limit rows if specified\n",
    "#     if max_rows is not None:\n",
    "#         result_df = result_df.iloc[:max_rows].copy()\n",
    "    \n",
    "#     # Initialize the API client\n",
    "#     client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com\")\n",
    "    \n",
    "#     # Initialize the new column\n",
    "#     result_df['input_generator'] = None\n",
    "    \n",
    "#     # Process each row with progress bar\n",
    "#     for idx, row in tqdm(result_df.iterrows(), total=len(result_df), desc=\"Generating input generators\"):\n",
    "#         if idx > 0 and idx % batch_size == 0:\n",
    "#             print(f\"Pausing for {sleep_time} seconds to avoid rate limits...\")\n",
    "#             time.sleep(sleep_time)\n",
    "        \n",
    "#         prompt = row['input_generator_prompt']\n",
    "#         if pd.isna(prompt) or not prompt.strip():\n",
    "#             print(f\"Skipping row {idx}: Empty prompt\")\n",
    "#             continue\n",
    "            \n",
    "#         try:\n",
    "#             # Call the Deepseek API\n",
    "#             response = client.chat.completions.create(\n",
    "#                 model=\"deepseek-chat\",\n",
    "#                 messages=[\n",
    "#                     {\"role\": \"system\", \"content\": \"You are an expert Python programmer. Provide only valid, runnable Python code.\"},\n",
    "#                     {\"role\": \"user\", \"content\": prompt}\n",
    "#                 ],\n",
    "#                 temperature=temperature,\n",
    "#                 stream=False\n",
    "#             )\n",
    "            \n",
    "#             # Extract the generated code\n",
    "#             generated_code = response.choices[0].message.content\n",
    "            \n",
    "#             # Store the response in the DataFrame\n",
    "#             result_df.at[idx, 'input_generator'] = generated_code\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error in row {idx}: {str(e)}\")\n",
    "    \n",
    "#     # Save progress to CSV (in case of interruption)\n",
    "#     result_df.to_csv('../generated_data/df_with_input_generators.csv', index=False)\n",
    "#     print(f\"Saved DataFrame with {len(result_df)} rows to df_with_input_generators.csv\")\n",
    "    \n",
    "#     return result_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8425794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parallel API calls with 5 workers, temperature=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parallel API calls: 100%|██████████| 10/10 [01:12<00:00,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DataFrame with 10 rows to ../generated_data\\df_with_input_generators.csv\n",
      "Results summary:\n",
      "  Success: 10 (100.0%)\n",
      "  Errors: 0 (0.0%)\n",
      "  Empty: 0 (0.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def call_deepseek_api_with_retry(client, prompt, temperature, max_retries=3, backoff_factor=2, timeout=30):\n",
    "    \"\"\"\n",
    "    Call the Deepseek API with retry logic and exponential backoff.\n",
    "    \n",
    "    Args:\n",
    "        client: OpenAI client instance\n",
    "        prompt: Prompt to send to the API\n",
    "        temperature: Temperature setting (0.0 to 1.0)\n",
    "        max_retries: Maximum number of retries on failure\n",
    "        backoff_factor: Factor to increase wait time between retries\n",
    "        timeout: Timeout in seconds for the API call\n",
    "        \n",
    "    Returns:\n",
    "        Generated code from Deepseek or error message\n",
    "    \"\"\"\n",
    "    if pd.isna(prompt) or not prompt.strip():\n",
    "        return None\n",
    "        \n",
    "    retries = 0\n",
    "    while retries <= max_retries:\n",
    "        try:\n",
    "            # Add small delay before API call to prevent rate limiting\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert Python programmer. Provide only valid, runnable Python code.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                stream=False,\n",
    "                timeout=timeout  # Add timeout to prevent hanging requests\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            if retries > max_retries:\n",
    "                return f\"# ERROR: {str(e)}\"\n",
    "                \n",
    "            # Calculate wait time with exponential backoff\n",
    "            wait_time = backoff_factor ** retries\n",
    "            print(f\"API call failed, retrying in {wait_time:.1f}s... ({str(e)})\")\n",
    "            time.sleep(wait_time)\n",
    "    \n",
    "    return \"# ERROR: Maximum retries exceeded\"\n",
    "\n",
    "def generate_input_generators_parallel(df, api_key, max_rows=None, temperature=0.3, max_workers=5, \n",
    "                                      save_interval=25, output_dir='../generated_data'):\n",
    "    \"\"\"\n",
    "    Generate input generators in parallel with improved robustness.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with input_generator_prompt column\n",
    "        api_key: Deepseek API key\n",
    "        max_rows: Maximum number of rows to process (None for all)\n",
    "        temperature: Temperature setting for the API\n",
    "        max_workers: Maximum number of parallel threads\n",
    "        save_interval: Save interim results every N completed items\n",
    "        output_dir: Directory to save output files\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with generated input_generator column\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Prepare the result DataFrame\n",
    "    result_df = df.copy()\n",
    "    if max_rows is not None:\n",
    "        result_df = result_df.iloc[:max_rows].copy()\n",
    "\n",
    "    # Initialize API client\n",
    "    client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com\")\n",
    "    prompts = result_df['input_generator_prompt'].tolist()\n",
    "\n",
    "    # Pre-allocate results list\n",
    "    results = [None] * len(prompts)\n",
    "    completed_count = 0\n",
    "    \n",
    "    # Start time for logging\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"Starting parallel API calls with {max_workers} workers, temperature={temperature}\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        futures = {\n",
    "            executor.submit(\n",
    "                call_deepseek_api_with_retry, \n",
    "                client, \n",
    "                prompt, \n",
    "                temperature\n",
    "            ): idx for idx, prompt in enumerate(prompts)\n",
    "        }\n",
    "        \n",
    "        # Process results as they complete\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Parallel API calls\"):\n",
    "            idx = futures[future]\n",
    "            results[idx] = future.result()\n",
    "            \n",
    "            # Increment completed count\n",
    "            completed_count += 1\n",
    "            \n",
    "            # Periodically save progress\n",
    "            if completed_count % save_interval == 0:\n",
    "                interim_df = result_df.copy()\n",
    "                interim_df['input_generator'] = results\n",
    "                \n",
    "                # Save to CSV with timestamp\n",
    "                timestamp = int(time.time())\n",
    "                interim_file = os.path.join(\n",
    "                    output_dir, \n",
    "                    f\"df_with_input_generators_interim_{completed_count}_{timestamp}.csv\"\n",
    "                )\n",
    "                \n",
    "                interim_df.to_csv(interim_file, index=False)\n",
    "                print(f\"\\nInterim progress saved ({completed_count}/{len(prompts)}) to {interim_file}\")\n",
    "                \n",
    "                # Also log some stats\n",
    "                elapsed = time.time() - start_time\n",
    "                rate = completed_count / elapsed\n",
    "                remaining = (len(prompts) - completed_count) / rate if rate > 0 else 0\n",
    "                \n",
    "                print(f\"Elapsed: {elapsed:.1f}s | Rate: {rate:.2f} items/s | Est. remaining: {remaining:.1f}s\")\n",
    "    \n",
    "    # Store results in DataFrame\n",
    "    result_df['input_generator'] = results\n",
    "    \n",
    "    # Save final results\n",
    "    final_file = os.path.join(output_dir, \"df_with_input_generators.csv\")\n",
    "    result_df.to_csv(final_file, index=False)\n",
    "    print(f\"Saved DataFrame with {len(result_df)} rows to {final_file}\")\n",
    "    \n",
    "    # Count successes and failures\n",
    "    success_count = sum(1 for r in results if r is not None and not str(r).startswith(\"# ERROR:\"))\n",
    "    error_count = sum(1 for r in results if r is not None and str(r).startswith(\"# ERROR:\"))\n",
    "    empty_count = sum(1 for r in results if r is None)\n",
    "    \n",
    "    print(f\"Results summary:\")\n",
    "    print(f\"  Success: {success_count} ({success_count/len(results)*100:.1f}%)\")\n",
    "    print(f\"  Errors: {error_count} ({error_count/len(results)*100:.1f}%)\")\n",
    "    print(f\"  Empty: {empty_count} ({empty_count/len(results)*100:.1f}%)\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Example usage:\n",
    "df_with_generators = generate_input_generators_parallel(\n",
    "    df=df,\n",
    "    api_key=key,\n",
    "    max_rows=10,       # Process 10 rows (adjust as needed)\n",
    "    temperature=0.3,     # Good balance for code generation\n",
    "    max_workers=5,       # Adjust based on your system and API limits\n",
    "    save_interval=50     # Save progress every 50 completions\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802206d6",
   "metadata": {},
   "source": [
    "### Remove ```python tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9082eccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of cleaned data:\n",
      "                                             context  \\\n",
      "0  In a 3D space, a drone is navigating towards a...   \n",
      "1  Given a differential equation and its initial ...   \n",
      "\n",
      "                                      reference_code  \\\n",
      "0  # import necessary packages\\nimport numpy as n...   \n",
      "1  # import necessary packages\\nimport math\\nimpo...   \n",
      "\n",
      "                              input_generator_prompt  \\\n",
      "0  \\nYou are an expert programmer tasked with cre...   \n",
      "1  \\nYou are an expert programmer tasked with cre...   \n",
      "\n",
      "                                     input_generator  \n",
      "0  import numpy as np\\nimport random\\n\\ndef input...  \n",
      "1  import random\\nimport math\\n\\ndef input_genera...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_code_block(code_text):\n",
    "    \"\"\"\n",
    "    Clean a code block by:\n",
    "    1. Removing ```python from the start\n",
    "    2. Replacing all \\n with spaces\n",
    "    3. Removing ``` from the end\n",
    "    \"\"\"\n",
    "    if pd.isna(code_text):\n",
    "        return code_text\n",
    "        \n",
    "    # Remove ```python from the start\n",
    "    if code_text.strip().startswith(\"```python\"):\n",
    "        code_text = code_text.replace(\"```python\", \"\", 1)\n",
    "    \n",
    "    # Remove ``` from the end\n",
    "    code_text = re.sub(r\"```$\", \"\", code_text.strip())\n",
    "    \n",
    "    return code_text.strip()\n",
    "\n",
    "# Load the DataFrame (if not already loaded)\n",
    "# df_with_generators = pd.read_csv('../generated_data/df_with_input_generators.csv')\n",
    "\n",
    "# Apply the cleaning function to the input_generator column\n",
    "df_with_generators['input_generator'] = df_with_generators['input_generator'].apply(clean_code_block)\n",
    "\n",
    "# Save the cleaned DataFrame\n",
    "df_with_generators.to_csv('../generated_data/df_with_clean_input_generators.csv', index=False)\n",
    "\n",
    "# Display sample of cleaned data\n",
    "print(\"Sample of cleaned data:\")\n",
    "print(df_with_generators.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b78f34",
   "metadata": {},
   "source": [
    "### creating IO pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b78036ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note 1: Currently a parameter max_attempts is manually set to 15 in the script template.\n",
    "This may not be a sufficiently large number for some cases, and the script may fail to generate the required number \n",
    "of examples.\n",
    "Note 2: There is no guarantee that there will be exactly num_examples examples generated. For many reasons errors \n",
    "can arrise (timeout, etc.). We need a larger subset \n",
    "Note 3: current progres bar formatting generates more than 500 output lines so you cannot track progress at a certain point.\n",
    "-> maybe reduce the number of lines printed for the final run \n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import signal\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "def generate_io_pairs_robust(df, max_rows=None, num_examples=5, timeout_seconds=60, parallel=False, n_processes=4):\n",
    "    \"\"\"\n",
    "    Generate I/O pairs using the robust approach, ensuring exactly num_examples examples when possible\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with context, reference_code, and input_generator columns\n",
    "        max_rows: Maximum number of rows to process (None for all rows)\n",
    "        num_examples: Number of I/O examples to generate per problem (default: 5)\n",
    "        timeout_seconds: Maximum execution time per problem in seconds\n",
    "        parallel: Whether to use parallel processing\n",
    "        n_processes: Number of processes to use if parallel=True\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with added column: io_pairs (always with exactly num_examples pairs when successful)\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original DataFrame\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Limit rows if specified\n",
    "    if max_rows is not None:\n",
    "        result_df = result_df.iloc[:max_rows].copy()\n",
    "    \n",
    "    # Initialize new column\n",
    "    result_df['io_pairs'] = None\n",
    "    \n",
    "    # Create temp directory for script execution\n",
    "    temp_dir = os.path.join(os.getcwd(), \"temp_scripts\")\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Generating exactly {num_examples} I/O pairs for {len(result_df)} rows...\")\n",
    "    \n",
    "    # Define the template for the script - NOTE: doubled curly braces to escape them\n",
    "    script_template = \"\"\"\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import collections\n",
    "import itertools\n",
    "import functools\n",
    "import operator\n",
    "import copy\n",
    "import bisect\n",
    "import sys\n",
    "import nltk\n",
    "from typing import List, Dict, Set, Tuple, Optional, Union, Any\n",
    "\n",
    "# For size checking without pympler dependency\n",
    "def strict_check_size(obj):\n",
    "    # Check for dict type\n",
    "    if isinstance(obj, dict):\n",
    "        if len(obj) >= 20:  # Check dict has fewer than 20 key-value pairs\n",
    "            return False\n",
    "        # Recursively check keys and values\n",
    "        for k, v in obj.items():\n",
    "            if not strict_check_size(k) or not strict_check_size(v):\n",
    "                return False\n",
    "\n",
    "    # Check for list, tuple, or set\n",
    "    elif isinstance(obj, (list, tuple, set)):\n",
    "        if len(obj) >= 20:  # Check if the length is less than 20\n",
    "            return False\n",
    "        # Recursively check each element\n",
    "        for item in obj:\n",
    "            if not strict_check_size(item):\n",
    "                return False\n",
    "\n",
    "    # Check for string\n",
    "    elif isinstance(obj, str):\n",
    "        if len(obj) >= 100:  # Check if string length is less than 100 characters\n",
    "            return False\n",
    "\n",
    "    # If all checks are passed, return True\n",
    "    return True\n",
    "\n",
    "# Print debug info\n",
    "print(\"DEBUG: Loading reference code and input generator...\")\n",
    "\n",
    "# Reference code (solution implementation)\n",
    "{reference_code}\n",
    "\n",
    "# Input generator\n",
    "{input_generator}\n",
    "\n",
    "print(\"DEBUG: Looking for main function...\")\n",
    "\n",
    "# Find the main function\n",
    "main_fn = None\n",
    "callable_funcs = []\n",
    "\n",
    "for name in list(globals().keys()):\n",
    "    if callable(globals()[name]) and name not in ['strict_check_size', 'input_generator']:\n",
    "        callable_funcs.append(name)\n",
    "        if name == 'main_solution':\n",
    "            main_fn = globals()['main_solution']\n",
    "            print(f\"DEBUG: Found main_solution function\")\n",
    "            break\n",
    "        elif 'main' in name.lower():\n",
    "            main_fn = globals()[name]\n",
    "            print(f\"DEBUG: Found function with 'main' in name: {{name}}\")\n",
    "            break\n",
    "\n",
    "if not main_fn and callable_funcs:\n",
    "    # Try any other callable function that's not input_generator\n",
    "    main_fn = globals()[callable_funcs[0]]\n",
    "    print(f\"DEBUG: Using alternative function: {{callable_funcs[0]}}\")\n",
    "\n",
    "if not main_fn:\n",
    "    print(\"DEBUG: Cannot find main function. Available functions:\")\n",
    "    for name in callable_funcs:\n",
    "        print(f\"DEBUG: - {{name}}\")\n",
    "    print(\"DEBUG: ABORTING\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Generate I/O pairs\n",
    "diff_inputs = []\n",
    "corr_outputs = []\n",
    "\n",
    "print(\"DEBUG: Generating I/O pairs...\")\n",
    "\n",
    "# Maximum attempts to get the required number of examples\n",
    "max_attempts = 15\n",
    "attempts = 0\n",
    "\n",
    "while len(diff_inputs) < {num_examples} and attempts < max_attempts:\n",
    "    attempts += 1\n",
    "    try:\n",
    "        # Generate candidate input\n",
    "        cand_input = input_generator()\n",
    "        \n",
    "        # Ensure inputs are unique and not too large\n",
    "        if cand_input not in diff_inputs and strict_check_size(cand_input):\n",
    "            try:\n",
    "                # Call the function with the input\n",
    "                print(f\"DEBUG: Calling main function with input {{attempts}} ({{len(diff_inputs)}}/{{{num_examples}}} examples generated)\")\n",
    "                cand_output = main_fn(**cand_input)\n",
    "                \n",
    "                # Check if output is valid and not too large\n",
    "                if strict_check_size(cand_output) and cand_output is not None:\n",
    "                    diff_inputs.append(cand_input)\n",
    "                    corr_outputs.append(cand_output)\n",
    "                    print(f\"DEBUG: Successfully generated example {{len(diff_inputs)}}/{{{num_examples}}}\")\n",
    "            except Exception as e:\n",
    "                print(f\"DEBUG: Error calling main function: {{str(e)}}\")\n",
    "                continue\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"DEBUG: Error generating input: {{str(e)}}\")\n",
    "        continue\n",
    "\n",
    "print(f\"DEBUG: Generated {{len(diff_inputs)}} I/O pairs after {{attempts}} attempts\")\n",
    "\n",
    "# Prepare the output - ensure we have exactly num_examples or fewer if we couldn't generate enough\n",
    "if len(diff_inputs) > 0:\n",
    "    assert len(diff_inputs) == len(corr_outputs)\n",
    "    # Limit to exactly num_examples if we have more (shouldn't happen with the loop above, but just in case)\n",
    "    if len(diff_inputs) > {num_examples}:\n",
    "        diff_inputs = diff_inputs[:{num_examples}]\n",
    "        corr_outputs = corr_outputs[:{num_examples}]\n",
    "    \n",
    "    iolist = [{{\"input\": diff_inputs[i], \"output\": corr_outputs[i]}} for i in range(len(diff_inputs))]\n",
    "    # Print the result with markers for extraction\n",
    "    print(\"[JSON IOS START]\" + json.dumps(iolist) + \"[JSON IOS END]\")\n",
    "else:\n",
    "    print(\"DEBUG: Failed to generate any valid I/O pairs\")\n",
    "    print(\"[JSON IOS START][]\" + \"[JSON IOS END]\")\n",
    "\"\"\"\n",
    "    \n",
    "    def process_row(idx, row):\n",
    "        \"\"\"Process a single DataFrame row to generate I/O pairs\"\"\"\n",
    "        if not row.get('reference_code') or not row.get('input_generator'):\n",
    "            print(f\"[Row {idx}] Missing reference_code or input_generator\")\n",
    "            return None\n",
    "        \n",
    "        # Create a temporary directory for each process in parallel mode\n",
    "        if parallel:\n",
    "            process_temp_dir = os.path.join(temp_dir, f\"proc_{os.getpid()}\")\n",
    "            os.makedirs(process_temp_dir, exist_ok=True)\n",
    "            this_temp_dir = process_temp_dir\n",
    "        else:\n",
    "            this_temp_dir = temp_dir\n",
    "        \n",
    "        # Create the script content\n",
    "        try:\n",
    "            script_content = script_template.format(\n",
    "                reference_code=row['reference_code'],\n",
    "                input_generator=row['input_generator'],\n",
    "                num_examples=num_examples\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[Row {idx}] Error formatting script: {str(e)}\")\n",
    "            return None\n",
    "        \n",
    "        # Write the script to a temporary file\n",
    "        script_path = os.path.join(this_temp_dir, f\"script_{idx}.py\")\n",
    "        with open(script_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(script_content)\n",
    "        \n",
    "        try:\n",
    "            # Execute the script as a separate process with timeout\n",
    "            # Start the subprocess in a new session (process group)\n",
    "            print(f\"[Row {idx}] Executing script...\")\n",
    "            if os.name == 'nt':  # Windows\n",
    "                process = subprocess.Popen(\n",
    "                    [sys.executable, script_path],\n",
    "                    stdout=subprocess.PIPE,\n",
    "                    stderr=subprocess.PIPE,\n",
    "                    text=True,\n",
    "                    creationflags=subprocess.CREATE_NEW_PROCESS_GROUP\n",
    "                )\n",
    "            else:  # Unix/Linux/Mac\n",
    "                process = subprocess.Popen(\n",
    "                    [sys.executable, script_path],\n",
    "                    stdout=subprocess.PIPE,\n",
    "                    stderr=subprocess.PIPE,\n",
    "                    text=True,\n",
    "                    start_new_session=True\n",
    "                )\n",
    "            \n",
    "            try:\n",
    "                stdout, stderr = process.communicate(timeout=timeout_seconds)\n",
    "            except subprocess.TimeoutExpired:\n",
    "                # Kill the process if it times out\n",
    "                print(f\"[Row {idx}] Process timed out after {timeout_seconds} seconds\")\n",
    "                if os.name == 'nt':  # Windows\n",
    "                    subprocess.call(['taskkill', '/F', '/T', '/PID', str(process.pid)])\n",
    "                else:  # Unix/Linux/Mac\n",
    "                    os.killpg(os.getpgid(process.pid), signal.SIGTERM)\n",
    "                process.wait()\n",
    "                return None\n",
    "            \n",
    "            # Extract I/O pairs from the output\n",
    "            start_marker = \"[JSON IOS START]\"\n",
    "            end_marker = \"[JSON IOS END]\"\n",
    "            \n",
    "            if start_marker in stdout and end_marker in stdout:\n",
    "                start_index = stdout.index(start_marker) + len(start_marker)\n",
    "                end_index = stdout.index(end_marker)\n",
    "                json_str = stdout[start_index:end_index].strip()\n",
    "                \n",
    "                # Parse the JSON data\n",
    "                try:\n",
    "                    io_pairs = json.loads(json_str)\n",
    "                    if io_pairs:\n",
    "                        print(f\"[Row {idx}] Successfully generated {len(io_pairs)} I/O pairs\")\n",
    "                        return io_pairs\n",
    "                    else:\n",
    "                        print(f\"[Row {idx}] Generated empty IO pairs list\")\n",
    "                        return None\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"[Row {idx}] JSON decode error\")\n",
    "                    print(f\"[Row {idx}] JSON string: {json_str[:100]}...\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(f\"[Row {idx}] No JSON markers found in output\")\n",
    "                print(f\"[Row {idx}] STDOUT: {stdout[:500]}...\")\n",
    "                print(f\"[Row {idx}] STDERR: {stderr[:500]}...\")\n",
    "                return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[Row {idx}] Error: {str(e)}\")\n",
    "            print(f\"[Row {idx}] Traceback: {traceback.format_exc()}\")\n",
    "            return None\n",
    "        finally:\n",
    "            # Clean up the temporary script file\n",
    "            if os.path.exists(script_path):\n",
    "                try:\n",
    "                    os.remove(script_path)\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # Process each row\n",
    "    if parallel and n_processes > 1:\n",
    "        # Parallel processing\n",
    "        from multiprocessing import Pool\n",
    "        \n",
    "        with Pool(processes=n_processes) as pool:\n",
    "            results = list(tqdm(\n",
    "                pool.starmap(\n",
    "                    process_row, \n",
    "                    [(idx, row) for idx, row in result_df.iterrows()]\n",
    "                ),\n",
    "                total=len(result_df)\n",
    "            ))\n",
    "        \n",
    "        # Update the DataFrame with results\n",
    "        for idx, io_pairs in enumerate(results):\n",
    "            result_df.iloc[idx, result_df.columns.get_loc('io_pairs')] = io_pairs\n",
    "    else:\n",
    "        # Sequential processing\n",
    "        for idx, row in tqdm(result_df.iterrows(), total=len(result_df)):\n",
    "            io_pairs = process_row(idx, row)\n",
    "            result_df.at[idx, 'io_pairs'] = io_pairs\n",
    "    \n",
    "    # Clean up the temporary directory\n",
    "    try:\n",
    "        shutil.rmtree(temp_dir)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def add_robust_io_pairs(df, num_examples=5, max_rows=None, timeout_seconds=60, parallel=False, n_processes=4):\n",
    "    \"\"\"\n",
    "    Add robust I/O pairs to a DataFrame, ensuring exactly num_examples examples when possible.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with context, reference_code, and input_generator columns\n",
    "        num_examples: Number of I/O examples to generate per row (default: 5)\n",
    "        max_rows: Maximum number of rows to process\n",
    "        timeout_seconds: Maximum seconds to allow for each row's execution\n",
    "        parallel: Whether to use parallel processing\n",
    "        n_processes: Number of processes for parallel execution\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with added io_pairs column\n",
    "    \"\"\"\n",
    "    return generate_io_pairs_robust(\n",
    "        df, \n",
    "        max_rows=max_rows, \n",
    "        num_examples=num_examples, \n",
    "        timeout_seconds=timeout_seconds,\n",
    "        parallel=parallel,\n",
    "        n_processes=n_processes\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14883b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating exactly 5 I/O pairs for 10 rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row 0] Executing script...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:03<00:30,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row 0] Successfully generated 5 I/O pairs\n",
      "[Row 1] Executing script...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:06<00:26,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row 1] Successfully generated 5 I/O pairs\n",
      "[Row 2] Executing script...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:09<00:22,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row 2] Successfully generated 5 I/O pairs\n",
      "[Row 3] Executing script...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:12<00:18,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row 3] Successfully generated 4 I/O pairs\n",
      "[Row 4] Executing script...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:15<00:15,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row 4] Successfully generated 5 I/O pairs\n",
      "[Row 5] Executing script...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:18<00:12,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row 5] Successfully generated 5 I/O pairs\n",
      "[Row 6] Executing script...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:21<00:09,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row 6] Successfully generated 5 I/O pairs\n",
      "[Row 7] Executing script...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:24<00:06,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row 7] Successfully generated 5 I/O pairs\n",
      "[Row 8] Executing script...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:27<00:03,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row 8] Successfully generated 5 I/O pairs\n",
      "[Row 9] Executing script...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:31<00:00,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row 9] Successfully generated 5 I/O pairs\n",
      "Processed 10 rows. Output written to ../generated_data/augmented_data_10.csv\n",
      "\n",
      "Sample I/O pairs for row 5\n",
      "[\n",
      "  {\n",
      "    \"input\": {\n",
      "      \"location\": [\n",
      "        39,\n",
      "        44\n",
      "      ],\n",
      "      \"initialFoodLevel\": 896,\n",
      "      \"food_locations\": [\n",
      "        [\n",
      "          6,\n",
      "          62\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"output\": {\n",
      "      \"food_level\": 896,\n",
      "      \"ant_count\": 0,\n",
      "      \"state\": \"HEALTHY\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"input\": {\n",
      "      \"location\": [\n",
      "        41,\n",
      "        6\n",
      "      ],\n",
      "      \"initialFoodLevel\": 155,\n",
      "      \"food_locations\": [\n",
      "        [\n",
      "          57,\n",
      "          47\n",
      "        ],\n",
      "        [\n",
      "          38,\n",
      "          92\n",
      "        ],\n",
      "        [\n",
      "          76,\n",
      "          25\n",
      "        ],\n",
      "        [\n",
      "          64,\n",
      "          75\n",
      "        ],\n",
      "        [\n",
      "          24,\n",
      "          16\n",
      "        ],\n",
      "        [\n",
      "          95,\n",
      "          26\n",
      "        ],\n",
      "        [\n",
      "          85,\n",
      "          78\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"output\": {\n",
      "      \"food_level\": 155,\n",
      "      \"ant_count\": 0,\n",
      "      \"state\": \"HEALTHY\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"input\": {\n",
      "      \"location\": [\n",
      "        2,\n",
      "        46\n",
      "      ],\n",
      "      \"initialFoodLevel\": 408,\n",
      "      \"food_locations\": [\n",
      "        [\n",
      "          82,\n",
      "          59\n",
      "        ],\n",
      "        [\n",
      "          1,\n",
      "          36\n",
      "        ],\n",
      "        [\n",
      "          13,\n",
      "          64\n",
      "        ],\n",
      "        [\n",
      "          85,\n",
      "          63\n",
      "        ],\n",
      "        [\n",
      "          28,\n",
      "          51\n",
      "        ],\n",
      "        [\n",
      "          91,\n",
      "          99\n",
      "        ],\n",
      "        [\n",
      "          44,\n",
      "          0\n",
      "        ],\n",
      "        [\n",
      "          37,\n",
      "          28\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"output\": {\n",
      "      \"food_level\": 408,\n",
      "      \"ant_count\": 0,\n",
      "      \"state\": \"HEALTHY\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"input\": {\n",
      "      \"location\": [\n",
      "        2,\n",
      "        61\n",
      "      ],\n",
      "      \"initialFoodLevel\": 43,\n",
      "      \"food_locations\": [\n",
      "        [\n",
      "          62,\n",
      "          28\n",
      "        ],\n",
      "        [\n",
      "          52,\n",
      "          79\n",
      "        ],\n",
      "        [\n",
      "          27,\n",
      "          54\n",
      "        ],\n",
      "        [\n",
      "          46,\n",
      "          60\n",
      "        ],\n",
      "        [\n",
      "          50,\n",
      "          6\n",
      "        ],\n",
      "        [\n",
      "          37,\n",
      "          88\n",
      "        ],\n",
      "        [\n",
      "          12,\n",
      "          67\n",
      "        ],\n",
      "        [\n",
      "          72,\n",
      "          11\n",
      "        ],\n",
      "        [\n",
      "          47,\n",
      "          81\n",
      "        ],\n",
      "        [\n",
      "          50,\n",
      "          83\n",
      "        ],\n",
      "        [\n",
      "          42,\n",
      "          37\n",
      "        ],\n",
      "        [\n",
      "          29,\n",
      "          37\n",
      "        ],\n",
      "        [\n",
      "          0,\n",
      "          18\n",
      "        ],\n",
      "        [\n",
      "          89,\n",
      "          50\n",
      "        ],\n",
      "        [\n",
      "          65,\n",
      "          57\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"output\": {\n",
      "      \"food_level\": 43,\n",
      "      \"ant_count\": 0,\n",
      "      \"state\": \"HEALTHY\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"input\": {\n",
      "      \"location\": [\n",
      "        16,\n",
      "        71\n",
      "      ],\n",
      "      \"initialFoodLevel\": 84,\n",
      "      \"food_locations\": [\n",
      "        [\n",
      "          57,\n",
      "          12\n",
      "        ],\n",
      "        [\n",
      "          67,\n",
      "          17\n",
      "        ],\n",
      "        [\n",
      "          43,\n",
      "          21\n",
      "        ],\n",
      "        [\n",
      "          68,\n",
      "          15\n",
      "        ],\n",
      "        [\n",
      "          27,\n",
      "          90\n",
      "        ],\n",
      "        [\n",
      "          69,\n",
      "          80\n",
      "        ],\n",
      "        [\n",
      "          2,\n",
      "          4\n",
      "        ],\n",
      "        [\n",
      "          4,\n",
      "          56\n",
      "        ],\n",
      "        [\n",
      "          33,\n",
      "          6\n",
      "        ],\n",
      "        [\n",
      "          30,\n",
      "          74\n",
      "        ],\n",
      "        [\n",
      "          63,\n",
      "          55\n",
      "        ],\n",
      "        [\n",
      "          32,\n",
      "          80\n",
      "        ],\n",
      "        [\n",
      "          0,\n",
      "          61\n",
      "        ],\n",
      "        [\n",
      "          80,\n",
      "          91\n",
      "        ],\n",
      "        [\n",
      "          28,\n",
      "          92\n",
      "        ],\n",
      "        [\n",
      "          72,\n",
      "          32\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"output\": {\n",
      "      \"food_level\": 84,\n",
      "      \"ant_count\": 0,\n",
      "      \"state\": \"HEALTHY\"\n",
      "    }\n",
      "  }\n",
      "]\n",
      "\n",
      "Sample I/O prompt:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your parameters\n",
    "NUM_EXAMPLES = 5  # Number of I/O pairs to generate per problem\n",
    "MAX_ROWS = 10  # Start with a small number for testing (None for all rows)\n",
    "TIMEOUT = 120  # Maximum seconds per problem <- 30 had 2 hours of runtime for 3000 rows\n",
    "USE_PARALLEL = False  # Set to True for faster processing if you have multiple cores\n",
    "N_PROCESSES = 4  # Number of parallel processes if USE_PARALLEL=True\n",
    "\n",
    "# Add robust I/O pairs to the DataFrame\n",
    "df_with_io = add_robust_io_pairs(\n",
    "    df_with_generators,\n",
    "    num_examples=NUM_EXAMPLES,\n",
    "    max_rows=MAX_ROWS,\n",
    "    timeout_seconds=TIMEOUT, \n",
    "    parallel=USE_PARALLEL,\n",
    "    n_processes=N_PROCESSES\n",
    ")\n",
    "\n",
    "# Save to jsonl file\n",
    "# output_jsonl = '../generated_data/augmented_data.jsonl'\n",
    "# df_with_io.to_json(output_jsonl, orient='records', lines=True, force_ascii=False)\n",
    "# print(f\"Processed {len(df_with_io)} rows. Output written to {output_jsonl}\")\n",
    "\n",
    "# Save to csv file\n",
    "output_csv = '../generated_data/augmented_data_10.csv'\n",
    "df_with_io.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "print(f\"Processed {len(df_with_io)} rows. Output written to {output_csv}\")\n",
    "\n",
    "# Show a sample of the results\n",
    "sample_idx = min(5, len(df_with_io)-1)  # Get a valid index\n",
    "if df_with_io.at[sample_idx, 'io_pairs']:\n",
    "    print(\"\\nSample I/O pairs for row\", sample_idx)\n",
    "    print(json.dumps(df_with_io.at[sample_idx, 'io_pairs'], indent=2))\n",
    "    \n",
    "    print(\"\\nSample I/O prompt:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f503dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2775 rows. Output written to ../processed_data/df_with_limited_io_pairs.csv\n",
      "\n",
      "Sample row 0 has 5 I/O pairs:\n",
      "[\n",
      "  {\n",
      "    \"input\": {\n",
      "      \"nums\": [\n",
      "        7,\n",
      "        -9,\n",
      "        6\n",
      "      ]\n",
      "    },\n",
      "    \"output\": [\n",
      "      [\n",
      "        6,\n",
      "        -9,\n",
      "        7\n",
      "      ],\n",
      "      [\n",
      "        -9,\n",
      "        6,\n",
      "        7\n",
      "      ],\n",
      "      [\n",
      "        7,\n",
      "        6,\n",
      "        -9\n",
      "      ],\n",
      "      [\n",
      "        6,\n",
      "        7,\n",
      "        -9\n",
      "      ],\n",
      "      [\n",
      "        -9,\n",
      "        7,\n",
      "        6\n",
      "      ],\n",
      "      [\n",
      "        7,\n",
      "        -9,\n",
      "        6\n",
      "      ]\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"input\": {\n",
      "      \"nums\": [\n",
      "        -3,\n",
      "        -10\n",
      "      ]\n",
      "    },\n",
      "    \"output\": [...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# def limit_io_pairs(df, max_examples=5):\n",
    "#     \"\"\"\n",
    "#     Limit the number of I/O pairs in each row to max_examples.\n",
    "    \n",
    "#     Args:\n",
    "#         df: DataFrame with an 'io_pairs' column\n",
    "#         max_examples: Maximum number of examples to keep\n",
    "        \n",
    "#     Returns:\n",
    "#         DataFrame with limited io_pairs\n",
    "#     \"\"\"\n",
    "#     # Create a copy to avoid modifying the original DataFrame\n",
    "#     result_df = df.copy()\n",
    "    \n",
    "#     # Function to limit the examples in a single row\n",
    "#     def limit_examples(io_pairs):\n",
    "#         if io_pairs is None:\n",
    "#             return None\n",
    "        \n",
    "#         # If it's a list of dictionaries with 'input' and 'output' keys\n",
    "#         if isinstance(io_pairs, list):\n",
    "#             return io_pairs[:max_examples]\n",
    "            \n",
    "#         return io_pairs\n",
    "    \n",
    "#     # Apply the function to each row\n",
    "#     result_df['io_pairs'] = result_df['io_pairs'].apply(limit_examples)\n",
    "    \n",
    "#     return result_df\n",
    "\n",
    "# # Limit the number of I/O pairs to 5 per row\n",
    "# df_with_limited_io = limit_io_pairs(df_with_io, max_examples=5)\n",
    "\n",
    "# # Save to CSV\n",
    "# output_csv = '../processed_data/df_with_limited_io_pairs.csv'\n",
    "# df_with_limited_io.to_csv(output_csv, index=False)\n",
    "# print(f\"Processed {len(df_with_limited_io)} rows. Output written to {output_csv}\")\n",
    "\n",
    "# # Print example to verify\n",
    "# if len(df_with_limited_io) > 0:\n",
    "#     sample_idx = 0\n",
    "#     sample_row = df_with_limited_io.iloc[sample_idx]\n",
    "#     if sample_row['io_pairs'] is not None:\n",
    "#         print(f\"\\nSample row {sample_idx} has {len(sample_row['io_pairs'])} I/O pairs:\")\n",
    "#         import json\n",
    "#         print(json.dumps(sample_row['io_pairs'], indent=2)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e4334b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
